{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMHsGcsWBKARKmSNDPWUl91",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joyce-ZhouY/ECE1512-ProjectB/blob/main/ProjectB_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iDIWP2O6vnjk"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import copy\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "# import utility classes\n",
        "import networks\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize args\n",
        "args = type('', (), {})()\n",
        "args.batch_train = 256\n",
        "args.batch_real = 256\n",
        "args.epoch_eval_train = 30 # the number of epoch to train a model with synthetic dataset \n",
        "args.epoch_train = 10 # the number of epoch to train a network\n",
        "args.lr_net = 0.01 # learning rate of the network\n",
        "args.lr_img = 0.1 # learning rate of synthetic dataset\n",
        "args.dsa_strategy = None\n",
        "args.num_eval = 5 # number of randomly initialized networks\n",
        "args.num_exp = 1 # number of experiments\n",
        "args.ipc = 10 # image per class\n",
        "args.outer_loop, args.inner_loop = utils.get_loops(args.ipc)\n",
        "args.batch_real = 256 # batch size for original dataset\n",
        "args.dsa = None\n",
        "args.method = 'DC'\n",
        "args.Iteration = 1000 # training iterations\n",
        "args.model = 'ConvNet'\n",
        "args.dataset = 'MNIST'\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "args.dsa_param = utils.ParamDiffAug()\n",
        "args.dsa = True if args.method == 'DSA' else False\n",
        "args.dc_aug_param = None\n",
        "args.dis_metric = 'ours' # distance metric\n",
        "args.data_path = 'data'\n",
        "args.save_path = 'result'\n",
        "args.eval_mode = 'S' # evaluate the synthetic data with the same model"
      ],
      "metadata": {
        "id": "5ci-ibgKwKpB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspired by https://arxiv.org/abs/2110.0418\n",
        "def distribution_matching():\n",
        "  if not os.path.exists(args.save_path):\n",
        "    os.mkdir(args.save_path)\n",
        "  \n",
        "  evaluate_pool = []\n",
        "  if args.eval_mode == 'S':\n",
        "    evaluate_pool = np.arange(0, args.Iteration+1, 500).tolist()\n",
        "  else:\n",
        "    evaluate_pool = [args.Iteration]\n",
        "\n",
        "  # load real dataset\n",
        "  channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = utils.get_dataset(args.dataset, args.data_path)\n",
        "  models = utils.get_eval_pool(args.eval_mode, args.model, args.model)\n",
        "\n",
        "  # record accuracy of each model\n",
        "  records = dict()\n",
        "\n",
        "  for model in models:\n",
        "    records[model] = []\n",
        "\n",
        "  # start experiments loops\n",
        "  for experiment in range(args.num_exp):\n",
        "    # orgnize real data\n",
        "    images_real = []\n",
        "    labels_real = []\n",
        "    for i in range(len(dst_train)):\n",
        "      images_real.append(torch.unsqueeze(dst_train[i][0], dim=0))\n",
        "\n",
        "    for i in range(len(dst_train)):\n",
        "      labels_real.append(dst_train[i][1])\n",
        "\n",
        "    class_index = [[] for c in range(num_classes)]\n",
        "    for n, label in enumerate(labels_real):\n",
        "      class_index[label].append(n)\n",
        "    # move inputs to device\n",
        "    images_real = torch.cat(images_real, dim=0).to(args.device)\n",
        "    labels_real = torch.tensor(labels_real, dtype=torch.long, device=args.device)\n",
        "\n",
        "    # implemente a method of ramdomly selecting n images from each class\n",
        "    def pick_images(c, n):\n",
        "      index = np.random.permutation(class_index[c])[:n]\n",
        "      return images_real[index]\n",
        "\n",
        "    # initialize synthetic dataset: randomly or gaussian noise\n",
        "    images_syn = torch.randn(\n",
        "        size = (args.ipc * num_classes, channel, im_size[0], im_size[1]),\n",
        "        dtype = torch.float,\n",
        "        requires_grad=True, \n",
        "        device=args.device\n",
        "    )\n",
        "    labels_syn = torch.tensor(\n",
        "        [np.ones(args.ipc) * n for n in range(num_classes)], \n",
        "        dtype=torch.long, \n",
        "        requires_grad=False, \n",
        "        device=args.device\n",
        "    ).view(-1)\n",
        "  \n",
        "    # if args.init = real, initilize synthetic data by ramdomly choosing from real data\n",
        "    if args.init == 'real':\n",
        "      for n in range(num_classes):\n",
        "        images_syn.data[n * args.ipc : (n + 1) * args.ipc] = pick_images(n, args.ipc).detach().data\n",
        "\n",
        "\n",
        "    # training process begins\n",
        "    optimizer_syn = torch.optim.SGD(\n",
        "      [images_syn, ], \n",
        "      lr=args.lr_img, \n",
        "      momentum=0.5) \n",
        "    optimizer_syn.zero_grad()\n",
        "    loss_fn = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "    for iter in range(args.Iteration + 1):\n",
        "      # evaluate synthetic set \n",
        "      if iter in evaluate_pool:\n",
        "        for model in models:\n",
        "          args.epoch_eval_train = 300\n",
        "        \n",
        "          accuracy = []\n",
        "          # loop over number of random model initialization\n",
        "          for eva in range(args.num_eval):\n",
        "            # load a network\n",
        "            net = utils.get_network(model, channel, num_classes, im_size).to(args.device)\n",
        "            _, acc_train, acc_test = utils.evaluate_synset(eva, net, images_syn, labels_syn, testloader, args)\n",
        "            accuracy.append(acc_test)\n",
        "          print('Evaluate synthetic data on model: %s, mean accuracy = %.4f'%(model, np.mean(accuracy)))\n",
        "\n",
        "          # save the last accuracy into records\n",
        "          if iter == args.Iteration:\n",
        "            records[model] += accuracy\n",
        "\n",
        "        #save synthetic data\n",
        "        path =  os.path.join(args.save_path, 'distribution_syn_%s_%s_%s_%dipc_exp%d_iter%d.png'%('random' if args.init == 'real' else 'noise', args.dataset, args.model, args.ipc, experiment, iter))\n",
        "        save_image(images_syn, path, nrow=args.ipc)\n",
        "\n",
        "      # train synthetic data\n",
        "      net = utils.get_network(args.model, channel, num_classes, im_size).to(args.device) # get a random model\n",
        "      net.train()\n",
        "      for param in list(net.parameters()):\n",
        "        param.requires_grad = False\n",
        "      \n",
        "      # parallel\n",
        "      embed = net.module.embed if torch.cuda.device_count() > 1 else net.embed\n",
        "\n",
        "      # update synthetic data\n",
        "      loss = torch.tensor(0.0).to(args.device)\n",
        "      for num in range(num_classes):\n",
        "        image_batch_real = pick_images(num, args.batch_real)\n",
        "        image_batch_syn = images_syn[num * args.ipc : (num + 1) * args.ipc].reshape((args.ipc, channel, im_size[0], im_size[1]))\n",
        "        out_real = embed(image_batch_real).detach()\n",
        "        out_syn = embed(image_batch_syn)\n",
        "\n",
        "        loss += torch.sum((torch.mean(out_real, dim=0) - torch.mean(out_syn, dim=0))**2)\n",
        "\n",
        "      optimizer_syn.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer_syn.step()\n",
        "         \n",
        "\n",
        "  for model in models:\n",
        "    accuracy = records[model]\n",
        "    print(\"Experiments = %d, model = %s, accuracy= %.2f\"%(args.num_exp, args.model, np.mean(accuracy)*100))\n",
        "  return images_syn, labels_syn"
      ],
      "metadata": {
        "id": "-_IJpMTiOKXl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.model = 'ConvNet'\n",
        "args.dataset = 'MNIST'\n",
        "args.eval_mode = 'S'\n",
        "args.init = 'real'\n",
        "syn = distribution_matching()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihFJOCm7XzMZ",
        "outputId": "d904d09a-09c4-4dc8-9bd4-0fac8d473aa2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-031b61fc5de0>:52: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  labels_syn = torch.tensor(\n",
            "<ipython-input-3-031b61fc5de0>:52: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  labels_syn = torch.tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-12-12 01:01:37] Evaluate_00: epoch = 0300 train time = 10 s train loss = 0.003749 train acc = 1.0000, test acc = 0.9126\n",
            "[2022-12-12 01:01:43] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.004039 train acc = 1.0000, test acc = 0.9018\n",
            "[2022-12-12 01:01:49] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.003731 train acc = 1.0000, test acc = 0.9048\n",
            "[2022-12-12 01:01:55] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.003970 train acc = 1.0000, test acc = 0.9139\n",
            "[2022-12-12 01:02:00] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.003943 train acc = 1.0000, test acc = 0.9096\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.9085\n",
            "[2022-12-12 01:03:12] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.004265 train acc = 1.0000, test acc = 0.9345\n",
            "[2022-12-12 01:03:18] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.004476 train acc = 1.0000, test acc = 0.9325\n",
            "[2022-12-12 01:03:24] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.004226 train acc = 1.0000, test acc = 0.9305\n",
            "[2022-12-12 01:03:29] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.004304 train acc = 1.0000, test acc = 0.9335\n",
            "[2022-12-12 01:03:35] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.004266 train acc = 1.0000, test acc = 0.9324\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.9327\n",
            "[2022-12-12 01:04:47] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.004126 train acc = 1.0000, test acc = 0.9363\n",
            "[2022-12-12 01:04:53] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.004337 train acc = 1.0000, test acc = 0.9390\n",
            "[2022-12-12 01:04:59] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.004347 train acc = 1.0000, test acc = 0.9340\n",
            "[2022-12-12 01:05:05] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.004248 train acc = 1.0000, test acc = 0.9321\n",
            "[2022-12-12 01:05:11] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.004466 train acc = 1.0000, test acc = 0.9331\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.9349\n",
            "Experiments = 1, model = ConvNet, accuracy= 93.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pthflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv1BVPcEs12Z",
        "outputId": "df325e74-c770-4410-c923-7512d13bc468"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pthflops\n",
            "  Downloading pthflops-0.4.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pthflops) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pthflops) (4.4.0)\n",
            "Installing collected packages: pthflops\n",
            "Successfully installed pthflops-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pthflops import count_ops\n",
        "args.dataset = 'MNIST'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = utils.get_dataset(args.dataset, args.data_path)\n",
        "args.model = 'ConvNet'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "\n",
        "def count_flops(dst_test):\n",
        "  flops = 0\n",
        "  images_test = []\n",
        "  labels_test = []\n",
        "  for i in range(len(dst_test)):\n",
        "    images_test.append(torch.unsqueeze(dst_test[i][0], dim=0))\n",
        "  for i in range(len(dst_test)):\n",
        "    labels_test.append(dst_test[i][1])\n",
        "  class_index = [[] for c in range(num_classes)]\n",
        "  for n, label in enumerate(labels_test):\n",
        "    class_index[label].append(n)\n",
        "  images_test = torch.cat(images_test, dim=0).to(args.device)\n",
        "  def pick_images(c, n):\n",
        "      index = np.random.permutation(class_index[c])[:n]\n",
        "      return images_test[index]\n",
        "  for n in range(num_classes):\n",
        "    img_batch = pick_images(n, 2560)\n",
        "    flops += count_ops(net, img_batch)[0]\n",
        "  return flops\n",
        "\n",
        "flops = count_flops(dst_test)\n",
        "print(\"The number of FLOPS = %.2f\"%(flops))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOXKi2fMs8H0",
        "outputId": "457c4bed-07ad-4f10-ae4d-e2395bd1a5ed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1284505600    \n",
            "features_2    256901120     \n",
            "features_3    128450560     \n",
            "features_4    37025873920   \n",
            "features_6    64225280      \n",
            "features_7    32112640      \n",
            "features_8    9256468480    \n",
            "features_10   16056320      \n",
            "features_11   8028160       \n",
            "classifier    20070410      \n",
            "-----------   -----------   \n",
            "Input size: (980, 1, 28, 28)\n",
            "48,092,692,490 FLOPs or approx. 48.09 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1487667200    \n",
            "features_2    297533440     \n",
            "features_3    148766720     \n",
            "features_4    42882007040   \n",
            "features_6    74383360      \n",
            "features_7    37191680      \n",
            "features_8    10720501760   \n",
            "features_10   18595840      \n",
            "features_11   9297920       \n",
            "classifier    23244810      \n",
            "-----------   -----------   \n",
            "Input size: (1135, 1, 28, 28)\n",
            "55,699,189,770 FLOPs or approx. 55.70 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1352663040    \n",
            "features_2    270532608     \n",
            "features_3    135266304     \n",
            "features_4    38990512128   \n",
            "features_6    67633152      \n",
            "features_7    33816576      \n",
            "features_8    9747628032    \n",
            "features_10   16908288      \n",
            "features_11   8454144       \n",
            "classifier    21135370      \n",
            "-----------   -----------   \n",
            "Input size: (1032, 1, 28, 28)\n",
            "50,644,549,642 FLOPs or approx. 50.64 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1323827200    \n",
            "features_2    264765440     \n",
            "features_3    132382720     \n",
            "features_4    38159319040   \n",
            "features_6    66191360      \n",
            "features_7    33095680      \n",
            "features_8    9539829760    \n",
            "features_10   16547840      \n",
            "features_11   8273920       \n",
            "classifier    20684810      \n",
            "-----------   -----------   \n",
            "Input size: (1010, 1, 28, 28)\n",
            "49,564,917,770 FLOPs or approx. 49.56 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1287127040    \n",
            "features_2    257425408     \n",
            "features_3    128712704     \n",
            "features_4    37101436928   \n",
            "features_6    64356352      \n",
            "features_7    32178176      \n",
            "features_8    9275359232    \n",
            "features_10   16089088      \n",
            "features_11   8044544       \n",
            "classifier    20111370      \n",
            "-----------   -----------   \n",
            "Input size: (982, 1, 28, 28)\n",
            "48,190,840,842 FLOPs or approx. 48.19 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1169162240    \n",
            "features_2    233832448     \n",
            "features_3    116916224     \n",
            "features_4    33701101568   \n",
            "features_6    58458112      \n",
            "features_7    29229056      \n",
            "features_8    8425275392    \n",
            "features_10   14614528      \n",
            "features_11   7307264       \n",
            "classifier    18268170      \n",
            "-----------   -----------   \n",
            "Input size: (892, 1, 28, 28)\n",
            "43,774,165,002 FLOPs or approx. 43.77 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1255669760    \n",
            "features_2    251133952     \n",
            "features_3    125566976     \n",
            "features_4    36194680832   \n",
            "features_6    62783488      \n",
            "features_7    31391744      \n",
            "features_8    9048670208    \n",
            "features_10   15695872      \n",
            "features_11   7847936       \n",
            "classifier    19619850      \n",
            "-----------   -----------   \n",
            "Input size: (958, 1, 28, 28)\n",
            "47,013,060,618 FLOPs or approx. 47.01 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1347420160    \n",
            "features_2    269484032     \n",
            "features_3    134742016     \n",
            "features_4    38839386112   \n",
            "features_6    67371008      \n",
            "features_7    33685504      \n",
            "features_8    9709846528    \n",
            "features_10   16842752      \n",
            "features_11   8421376       \n",
            "classifier    21053450      \n",
            "-----------   -----------   \n",
            "Input size: (1028, 1, 28, 28)\n",
            "50,448,252,938 FLOPs or approx. 50.45 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1276641280    \n",
            "features_2    255328256     \n",
            "features_3    127664128     \n",
            "features_4    36799184896   \n",
            "features_6    63832064      \n",
            "features_7    31916032      \n",
            "features_8    9199796224    \n",
            "features_10   15958016      \n",
            "features_11   7979008       \n",
            "classifier    19947530      \n",
            "-----------   -----------   \n",
            "Input size: (974, 1, 28, 28)\n",
            "47,798,247,434 FLOPs or approx. 47.80 GFLOPs\n",
            "Operation     OPS           \n",
            "------------  ------------  \n",
            "features_0    1322516480    \n",
            "features_2    264503296     \n",
            "features_3    132251648     \n",
            "features_4    38121537536   \n",
            "features_6    66125824      \n",
            "features_7    33062912      \n",
            "features_8    9530384384    \n",
            "features_10   16531456      \n",
            "features_11   8265728       \n",
            "classifier    20664330      \n",
            "-----------   -----------   \n",
            "Input size: (1009, 1, 28, 28)\n",
            "49,515,843,594 FLOPs or approx. 49.52 GFLOPs\n",
            "The number of FLOPS = 490741760100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train a network with syn data and test with real data\n",
        "\n",
        "# testing data\n",
        "args.dataset = 'MNIST'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = utils.get_dataset(args.dataset, args.data_path)\n",
        "# net\n",
        "args.model = 'ConvNet'\n",
        "net = utils.get_network(args.model,channel=channel,num_classes=num_classes,im_size=im_size).to(args.device)\n",
        "it_eval = args.num_eval\n",
        "\n",
        "# images_train = syn[0].to(args.device)\n",
        "# labels_train = syn[1].to(args.device)\n",
        "images_train, labels_train = copy.deepcopy(syn[0].detach()), copy.deepcopy(syn[1].detach())\n",
        "dst_train = utils.TensorDataset(images_train, labels_train)\n",
        "\n",
        "_, acc_train, acc_test = utils.evaluate_dataset(it_eval,net,dst_train,testloader,args)\n",
        "print(\"test with real dataset, accuracy = %.4f\"%(acc_test))\n",
        "\n",
        "flops = count_ops(net, images_train)[0]\n",
        "print(\"The number of FLOPS = %.2f\"%(flops))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviEJcSdleZp",
        "outputId": "7d2df8cb-595e-4c18-ba61-ca887ad3b7ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-12-12 01:27:07] Evaluate_05: epoch = 0010 train time = 0 s train loss = 1.214679 train acc = 0.8700, test acc = 0.8477\n",
            "test with real dataset, accuracy = 0.8477\n",
            "Operation     OPS          \n",
            "------------  -----------  \n",
            "features_0    131072000    \n",
            "features_2    26214400     \n",
            "features_3    13107200     \n",
            "features_4    3778150400   \n",
            "features_6    6553600      \n",
            "features_7    3276800      \n",
            "features_8    944537600    \n",
            "features_10   1638400      \n",
            "features_11   819200       \n",
            "classifier    2048010      \n",
            "-----------   ----------   \n",
            "Input size: (100, 1, 28, 28)\n",
            "4,907,417,610 FLOPs or approx. 4.91 GFLOPs\n",
            "The number of FLOPS = 4907417610.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.model = 'ConvNet'\n",
        "args.dataset = 'MNIST'\n",
        "args.eval_mode = 'S'\n",
        "args.init = 'noise'\n",
        "syn_noise = distribution_matching()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARfLBq5U9DDS",
        "outputId": "ad0010ce-2ace-40dd-b0aa-9a0f48b3d0f1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-031b61fc5de0>:52: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  labels_syn = torch.tensor(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-12-12 01:30:58] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.004619 train acc = 1.0000, test acc = 0.1065\n",
            "[2022-12-12 01:31:03] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.004660 train acc = 1.0000, test acc = 0.1075\n",
            "[2022-12-12 01:31:09] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.004640 train acc = 1.0000, test acc = 0.0765\n",
            "[2022-12-12 01:31:15] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.004846 train acc = 1.0000, test acc = 0.0646\n",
            "[2022-12-12 01:31:21] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.004556 train acc = 1.0000, test acc = 0.0940\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.0898\n",
            "[2022-12-12 01:32:33] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.003946 train acc = 1.0000, test acc = 0.8811\n",
            "[2022-12-12 01:32:39] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.004148 train acc = 1.0000, test acc = 0.8841\n",
            "[2022-12-12 01:32:45] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.003763 train acc = 1.0000, test acc = 0.8694\n",
            "[2022-12-12 01:32:51] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.003911 train acc = 1.0000, test acc = 0.8881\n",
            "[2022-12-12 01:32:56] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.003984 train acc = 1.0000, test acc = 0.8782\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.8802\n",
            "[2022-12-12 01:34:08] Evaluate_00: epoch = 0300 train time = 3 s train loss = 0.003713 train acc = 1.0000, test acc = 0.9046\n",
            "[2022-12-12 01:34:14] Evaluate_01: epoch = 0300 train time = 3 s train loss = 0.003902 train acc = 1.0000, test acc = 0.8985\n",
            "[2022-12-12 01:34:20] Evaluate_02: epoch = 0300 train time = 3 s train loss = 0.003821 train acc = 1.0000, test acc = 0.9007\n",
            "[2022-12-12 01:34:26] Evaluate_03: epoch = 0300 train time = 3 s train loss = 0.003858 train acc = 1.0000, test acc = 0.9001\n",
            "[2022-12-12 01:34:32] Evaluate_04: epoch = 0300 train time = 3 s train loss = 0.003651 train acc = 1.0000, test acc = 0.9022\n",
            "Evaluate synthetic data on model: ConvNet, mean accuracy = 0.9012\n",
            "Experiments = 1, model = ConvNet, accuracy= 90.12\n"
          ]
        }
      ]
    }
  ]
}